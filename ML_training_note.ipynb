{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zVSj2wrgmTjOKNYw2C1qsuseMGdptOaf",
      "authorship_tag": "ABX9TyM9Rk8M6G79E7OFc+ChDunJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JS-Choi513/Server_IO_prediction_by_machine_learning_method/blob/main/ML_training_note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSN4AgSLeeMf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8l3IRO2YFeCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "trace_data = pd.read_csv(\"/content/drive/MyDrive/DATA/CAMRESWMSA03-lvm1.csv\")\n",
        "trace_data = trace_data.drop('Type', axis=1)\n",
        "trace_data = trace_data.drop('DiskNumber', axis=1)\n",
        "trace_data = trace_data.drop('Hostname', axis=1)\n",
        "trace_data = trace_data[['Timestamp', 'Offset','ResponseTime','Size']]\n",
        "trace_data.boxplot(column=['Size'])\n",
        "trace_data.hist(column=['Size'])\n",
        "print(trace_data.head())\n",
        "\n",
        "Q1 = trace_data.quantile(q=0.25)\n",
        "Q3 = trace_data.quantile(q=0.75)\n",
        "print(Q1)\n",
        "print(Q3)\n",
        "IQR = Q3-Q1\n",
        "print(IQR)\n",
        "IQR_df = trace_data\n"
      ],
      "metadata": {
        "id": "OF2vnam2g_T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BsXGOjVG--p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "IQR_df = trace_data[(trace_data['ResponseTime'] <= Q3['ResponseTime']+1.5*IQR['ResponseTime']) & (trace_data['ResponseTime'] >= Q1['ResponseTime']-1.5*IQR['ResponseTime'])]\n",
        "IQR_df = IQR_df[(IQR_df['Offset'] <= Q3['Offset']+1.5*IQR['Offset']) & (IQR_df['Offset'] >= Q1['Offset']-1.5*IQR['Offset'])]\n",
        "IQR_df = IQR_df[(IQR_df['Timestamp'] <= Q3['Timestamp']+1.5*IQR['Timestamp']) & (IQR_df['Timestamp'] >= Q1['Timestamp']-1.5*IQR['Timestamp'])]\n",
        "IQR_df = IQR_df[(IQR_df['Size'] <= Q3['Size']+1.5*IQR['Size']) & (IQR_df['Size'] >= Q1['Size']-1.5*IQR['Size'])]\n",
        "IQR_df = IQR_df[['ResponseTime', 'Offset','Timestamp','Size']]\n",
        "\n",
        "print('original_df :', len(trace_data))\n",
        "print('IQR_df :', len(IQR_df))\n",
        "print(IQR_df)\n",
        "'''"
      ],
      "metadata": {
        "id": "ZgWNADAmmKqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5qZoAU8mnXzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IQR_df.boxplot(column=['Size'])\n"
      ],
      "metadata": {
        "id": "7qTgn1Kgk2Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IQR_df.boxplot(column=['ResponseTime', 'Offset','Timestamp','Size'])\n",
        "print(IQR_df.head())"
      ],
      "metadata": {
        "id": "QrzUIKJQntzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trace_data.head()\n",
        "#trace_data.describe()\n",
        "trace_data.info()"
      ],
      "metadata": {
        "id": "QG3pI4vkguu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trace_data_io_encoded = trace_data['Type'].replace(['Read','Write'],[0,1])\n",
        "trace_data['Type'] = trace_data_io_encoded\n",
        "print(\"Min size : \", min(trace_data[\"Size\"]))\n",
        "print(\"Max size : \", max(trace_data[\"Size\"]))\n",
        "print(\"2^9 ~ 2^20\")\n",
        "#trace_data.plot(kind=\"line\", x = \"Timestamp\", y=\"Size\")\n",
        "#trace_data.plot(kind=\"scatter\", x = \"Timestamp\", y= \"Size\")\n",
        "#trace_data.plot(kind=\"line\", x = \"Timestamp\", y=\"Offset\")\n",
        "#trace_data.plot(kind=\"line\", x = \"Timestamp\", y=\"ResponseTime\")\n",
        "#trace_data.plot(kind=\"scatter\", x = \"Size\", y=\"ResponseTime\")\n",
        "#trace_data.plot(kind=\"scatter\", x = \"Size\", y=\"ResponseTime\", alpha=0.1)\n",
        "#trace_data.plot(kind=\"scatter\", x = \"ResponseTime\", y=\"Offset\", alpha=0.1)"
      ],
      "metadata": {
        "id": "dr14_KFSyR8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IQR_df['Type'] = trace_data_io_encoded\n",
        "print(\"Min size : \", min(IQR_df[\"Size\"]))\n",
        "print(\"Max size : \", max(IQR_df[\"Size\"]))\n",
        "print(\"2^9 ~ 2^20\")"
      ],
      "metadata": {
        "id": "YkJDJdCyn8nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trace_data.plot(kind=\"scatter\", x = \"ResponseTime\", y=\"Size\")\n",
        "IQR_df.head()"
      ],
      "metadata": {
        "id": "ivD5qJab6wjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkrOG5Y4n8F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "#attributes = [\"Timestamp\", \"Offset\",\t\"Size\",\t\"ResponseTime\"]\n",
        "#scatter_matrix(trace_data[attributes], figsize=(12,8))\n",
        "from sklearn.model_selection import train_test_split\n",
        "IQR_df.dropna(axis=0)\n",
        "\n",
        "train_set, test_set = train_test_split(IQR_df, test_size=0.2)\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "#split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "#for train_index, test_index in split.split(train_set, train_set[\"Size\"]):\n",
        "#  strat_train_set = train_set.loc[train_index]\n",
        "#  strat_test_set = train_set.loc[test_index]\n",
        "#trace = train_set.drop(\"DiskNumber\", axis=1)\n",
        "#trace = trace.drop(\"Hostname\", axis=1)\n",
        "#trace = trace.drop(\"Type\", axis=1)\n",
        "train_set = train_set[:300000]\n",
        "print(train_set.head())\n",
        "trace_label = train_set[\"Size\"].copy()\n",
        "trace_label = trace_label[:300000]\n",
        "#test_trace = test_set.drop(\"DiskNumber\", axis=1)\n",
        "#test_trace = test_trace.drop(\"Hostname\", axis=1)\n",
        "#test_trace = test_trace.drop(\"Type\", axis=1)\n",
        "test_trace = test_set[:1000]\n",
        "test_label = test_set[\"Size\"].copy()\n",
        "test_label = test_label[:1000]\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#lin_reg = LinearRegression()\n",
        "#lin_reg.fit(trace, trace_label)\n",
        "#request_size_prediction = lin_reg.predict(trace)\n",
        "#lin_mse = mean_squared_error(trace_label, request_size_prediction)\n",
        "#lin_rmse = np.sqrt(lin_mse)\n",
        "#lin_rmse"
      ],
      "metadata": {
        "id": "ZRin-rFxTA4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#trace_data_io_encoded = encoder.fit_transform(trace_data_io)\n",
        "\n",
        "train_set.head()"
      ],
      "metadata": {
        "id": "W6GGeIgCYk2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Input scale\n",
        "\n",
        "\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_x.fit(train_set.iloc[:, :-1])\n",
        "\n",
        "train_set.iloc[:, :-1] = scaler_x.transform(train_set.iloc[:, :-1])\n",
        "test_set.iloc[:, :-1] = scaler_x.transform(test_set.iloc[:, :-1])\n",
        "\n",
        "# Output scale\n",
        "scaler_y = MinMaxScaler()\n",
        "#scaler_y.fit(trace.iloc[:, [-1]])\n",
        "scaler_y.fit(train_set.iloc[:, [-1]])\n",
        "\n",
        "train_set.iloc[:, -1] = scaler_y.transform(train_set.iloc[:, [-1]])\n",
        "test_set.iloc[:,-1] = scaler_y.transform(test_set.iloc[:, [-1]])\n",
        "\n",
        "print(train_set.head())\n",
        "#print(test_trace.head)\n",
        "\n",
        "train_set.boxplot(column=['ResponseTime', 'Offset','Timestamp','Size'])\n",
        "#test_trace.boxplot(column=['ResponseTime','Offset','Timestamp','Size'])"
      ],
      "metadata": {
        "id": "wbxJmjPa6mf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "X3p21UMU13vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset \n",
        "from torch.utils.data import DataLoader \n",
        "\n",
        "# 데이터셋 생성 \n",
        "def build_dataset(time_series, seq_length):\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(0, len(time_series)-seq_length):\n",
        "        _x = time_series[i:i+seq_length, :]\n",
        "        _y = time_series[i+seq_length, [2]]\n",
        "        #print(_x, \"-->\",_y)\n",
        "        dataX.append(_x)\n",
        "        dataY.append(_y)\n",
        "\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "trainX, trainY = build_dataset(np.array(train_set), 10)\n",
        "testX, testY = build_dataset(np.array(test_set), 10)\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "trainX_tensor = torch.FloatTensor(trainX).to(device)\n",
        "trainY_tensor = torch.FloatTensor(trainY).to(device)\n",
        "\n",
        "print(trainX_tensor)\n",
        "print(trainY_tensor)\n",
        "\n",
        "testX_tensor = torch.FloatTensor(testX).to(device)\n",
        "testY_tensor = torch.FloatTensor(testY).to(device)\n",
        "\n",
        "dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
        "\n",
        "dataloader = DataLoader(dataset,\n",
        "                        batch_size=256,\n",
        "                        shuffle=True,  \n",
        "                        drop_last=True)"
      ],
      "metadata": {
        "id": "eIqwa7AM16fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dim = 4\n",
        "hidden_dim = 8\n",
        "output_dim = 1 \n",
        "learning_rate = 0.0001\n",
        "nb_epochs = 100\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, seq_len, output_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.output_dim = output_dim\n",
        "        self.layers = layers\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers,\n",
        "                            # dropout = 0.1,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim, bias = True) \n",
        "        \n",
        "    def reset_hidden_state(self): \n",
        "        self.hidden = (\n",
        "                torch.zeros(self.layers, self.seq_len, self.hidden_dim),\n",
        "                torch.zeros(self.layers, self.seq_len, self.hidden_dim))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x, _status = self.lstm(x)\n",
        "        x = self.fc(x[:, -1])\n",
        "        return x"
      ],
      "metadata": {
        "id": "UBSe6XoD18RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, train_df, num_epochs = None, lr = None, verbose = 10, patience = 10):\n",
        "     \n",
        "    criterion = nn.MSELoss().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
        "    nb_epochs = num_epochs\n",
        "    \n",
        "    train_hist = np.zeros(nb_epochs)\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        avg_cost = 0\n",
        "        total_batch = len(train_df)\n",
        "        \n",
        "        for batch_idx, samples in enumerate(train_df):\n",
        "\n",
        "            x_train, y_train = samples\n",
        "            \n",
        "            model.reset_hidden_state()\n",
        "            \n",
        "            outputs = model(x_train)\n",
        "                \n",
        "            loss = torch.sqrt(criterion(outputs, y_train))\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            avg_cost += loss/total_batch\n",
        "               \n",
        "        train_hist[epoch] = avg_cost        \n",
        "        \n",
        "        if epoch % verbose == 0:\n",
        "            print('Epoch:', '%04d' % (epoch), 'train loss :', '{:.4f}'.format(avg_cost))\n",
        "        if (epoch % patience == 0) & (epoch != 0):\n",
        "            if train_hist[epoch-patience] < train_hist[epoch]:\n",
        "                print('\\n Early Stopping')\n",
        "               \n",
        "                break\n",
        "            \n",
        "    return model.eval(), train_hist"
      ],
      "metadata": {
        "id": "2lP7rYjN196c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "net = Net(data_dim, hidden_dim, 10, output_dim, 4)#.to(device)\n",
        "model, train_hist = train_model(net, dataloader, num_epochs = nb_epochs, lr = learning_rate, verbose = 20, patience = 10)"
      ],
      "metadata": {
        "id": "A6cdWoLS2A0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_hist, label=\"Training loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3ZWUzE3dV0z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with torch.no_grad(): \n",
        "    pred = []\n",
        "    for pr in range(len(testX_tensor)):\n",
        "\n",
        "        model.reset_hidden_state()\n",
        "\n",
        "        predicted = model(torch.unsqueeze(testX_tensor[pr], 0))\n",
        "        predicted = torch.flatten(predicted).item()\n",
        "        pred.append(predicted)\n",
        "    \n",
        "    device = torch.device(\"cpu\")\n",
        "  \n",
        "    pred_inverse = np.array(pred).reshape(-1, 1)\n",
        "    testY_inverse = np.array(testY_tensor)\n"
      ],
      "metadata": {
        "id": "S9wJZzMIXfGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,3))\n",
        "plt.plot(np.arange(len(pred_inverse)), pred_inverse, label = 'pred')\n",
        "plt.title(\"Prediction plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KR5AkUq4XmfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,3))\n",
        "plt.plot(np.arange(len(testY_inverse)), testY_inverse, label = 'true')\n",
        "plt.title(\"Label plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RctlTwXyeD2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trace_data.plot(kind=\"scatter\", x = \"Type\", y=\"ResponseTime\", alpha=0.1)\n",
        "trace_data.plot(kind=\"scatter\", x =\"Type\", y=\"Size\", alpha=0.1,\n",
        "                c=\"Offset\",  label=\"Request size\", \n",
        "                 cmap=plt.get_cmap(\"jet\"), colorbar=True)\n",
        "plt.legend()\n",
        "trace_data.plot(kind=\"scatter\", x = \"ResponseTime\", y=\"Type\")"
      ],
      "metadata": {
        "id": "6yzdhVoeenXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trace_data.dropna(axis=0)\n",
        "\n",
        "train_set, test_set = train_test_split(trace_data, test_size=0.2, random_state=42)\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "trace = train_set.drop(\"Size\", axis=1)\n",
        "trace = trace.drop(\"Hostname\", axis=1)\n",
        "trace_label = train_set[\"Size\"].copy()\n",
        "test_trace = test_set.drop(\"Size\", axis=1)\n",
        "test_trace = test_trace.drop(\"Hostname\", axis=1)\n",
        "test_label = test_set[\"Size\"].copy()\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(trace, trace_label)\n",
        "request_size_prediction = lin_reg.predict(trace)\n",
        "lin_mse = mean_squared_error(trace_label, request_size_prediction)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ],
      "metadata": {
        "id": "PHOd_SqxkxI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(trace, trace_label)\n",
        "size_predictions = tree_reg.predict(trace)\n",
        "tree_mse = mean_squared_error(trace_label, size_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "print(tree_rmse)"
      ],
      "metadata": {
        "id": "W7O2CP0FEnO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "def display_score(scores):\n",
        "  print(\"Scores:\", scores)\n",
        "  print(\"Mean:\", scores.mean())\n",
        "  print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "scores = cross_val_score(tree_reg, trace, trace_label, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "display_score(rmse_scores)\n",
        "print(\"\")\n",
        "lin_scores = cross_val_score(lin_reg, trace, trace_label, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_score(lin_rmse_scores)"
      ],
      "metadata": {
        "id": "KWOaOJl0nMXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsrfMwCe69oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "my_predictions = {}\n",
        "my_pred = None\n",
        "my_actual = None\n",
        "my_name = None\n",
        "\n",
        "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
        "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
        "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
        "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
        "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
        "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
        "         ]\n",
        "\n",
        "def plot_predictions(name_, pred, actual):\n",
        "    df = pd.DataFrame({'prediction': pred, 'actual': test_label})\n",
        "    df = df.sort_values(by='actual').reset_index(drop=True)\n",
        "\n",
        "    plt.figure(figsize=(11, 8))\n",
        "    plt.scatter(df.index, df['prediction'], marker='x', color='r')\n",
        "    \n",
        "    plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black')\n",
        "    plt.ylabel('Request Size')\n",
        "    plt.xlabel('Index')\n",
        "    plt.title(name_, fontsize=15)\n",
        "    plt.legend(['prediction', 'actual'], fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "def rmse_eval(name_, pred, actual):\n",
        "    global my_predictions, colors, my_pred, my_actual, my_name\n",
        "    \n",
        "    my_name = name_\n",
        "    my_pred = pred\n",
        "    my_actual = actual\n",
        "\n",
        "    plot_predictions(name_, pred, actual)\n",
        "\n",
        "    mse =np.sqrt( mean_squared_error(pred, actual))\n",
        "    my_predictions[name_] = mse\n",
        "\n",
        "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    df = pd.DataFrame(y_value, columns=['model', 'rmse'])\n",
        "    print(df)\n",
        "    min_ = df['rmse'].min() - 10\n",
        "    max_ = df['rmse'].max() + 10\n",
        "    \n",
        "    length = len(df) / 2\n",
        "\n",
        "    plt.figure(figsize=(9, length))\n",
        "    ax = plt.subplot()\n",
        "    ax.set_yticks(np.arange(len(df)))\n",
        "    ax.set_yticklabels(df['model'], fontsize=12)\n",
        "    bars = ax.barh(np.arange(len(df)), df['rmse'], height=0.3)\n",
        "    \n",
        "    for i, v in enumerate(df['rmse']):\n",
        "        idx = np.random.choice(len(colors))\n",
        "        bars[i].set_color(colors[idx])\n",
        "        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=12, fontweight='bold', verticalalignment='center')\n",
        "        \n",
        "    plt.title('RMSE Error', fontsize=16)\n",
        "    plt.xlim(min_, max_)\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "def add_model(name_, pred, actual):\n",
        "    global my_predictions, my_pred, my_actual, my_name\n",
        "    my_name = name_\n",
        "    my_pred = pred\n",
        "    my_actual = actual\n",
        "    \n",
        "    mse = mean_squared_error(pred, actual)\n",
        "    my_predictions[name_] = mse\n",
        "\n",
        "def remove_model(name_):\n",
        "    global my_predictions\n",
        "    try:\n",
        "        del my_predictions[name_]\n",
        "    except KeyError:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def plot_all():\n",
        "    global my_predictions, my_pred, my_actual, my_name\n",
        "    \n",
        "    plot_predictions(my_name, my_pred, my_actual)\n",
        "    \n",
        "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    df = pd.DataFrame(y_value, columns=['model', 'rmse'])\n",
        "    print(df)\n",
        "    min_ = df['rmse'].min() - 10\n",
        "    max_ = df['rmse'].max() + 10\n",
        "    \n",
        "    length = len(df) / 2\n",
        "    \n",
        "    plt.figure(figsize=(9, length))\n",
        "    ax = plt.subplot()\n",
        "    ax.set_yticks(np.arange(len(df)))\n",
        "    ax.set_yticklabels(df['model'], fontsize=12)\n",
        "    bars = ax.barh(np.arange(len(df)), df['rmse'], height=0.3)\n",
        "    \n",
        "    for i, v in enumerate(df['rmse']):\n",
        "        idx = np.random.choice(len(colors))\n",
        "        bars[i].set_color(colors[idx])\n",
        "        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=12, fontweight='bold', verticalalignment='center')\n",
        "        \n",
        "    plt.title('RMSE Error', fontsize=16)\n",
        "    plt.xlim(min_, max_)\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "K5ky4r7N_vtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "2LngUNVO_i12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(trace, trace_label)\n",
        "pred = linear_reg.predict(test_trace)\n",
        "rmse_eval('LinearRegression', pred, test_label)"
      ],
      "metadata": {
        "id": "eLETIGZO_yYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha=0.1)\n",
        "ridge.fit(trace, trace_label)\n",
        "pred = ridge.predict(test_trace)\n",
        "rmse_eval('Ridge(alpha=0.1)', pred, test_label)"
      ],
      "metadata": {
        "id": "5tqUDaW9FdVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=0.01)\n",
        "lasso.fit(trace, trace_label)\n",
        "pred = lasso.predict(test_trace)\n",
        "rmse_eval('Lasso(alpha=0.01)', pred, test_label)"
      ],
      "metadata": {
        "id": "4MefQAGGFq4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet = ElasticNet(alpha=0.01, l1_ratio=0.8)\n",
        "elasticnet.fit(trace, trace_label)\n",
        "pred = elasticnet.predict(test_trace)\n",
        "rmse_eval('ElasticNet(alpha=0.1, l1_ratio=0.8)', pred, test_label)   "
      ],
      "metadata": {
        "id": "4ZjxOrNjGNK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "elasticnet_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    ElasticNet(alpha=0.01, l1_ratio=0.8)\n",
        ")\n",
        "elasticnet_pipeline.fit(trace, trace_label)\n",
        "elasticnet_pred = elasticnet_pipeline.predict(test_trace)\n",
        "rmse_eval('Standard ElasticNet', elasticnet_pred, test_label)"
      ],
      "metadata": {
        "id": "Js6eILszGdqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_pipeline = make_pipeline(\n",
        "    PolynomialFeatures(degree=2, include_bias=False),\n",
        "    ElasticNet(alpha=0.1, l1_ratio=0.2)\n",
        ")\n",
        "poly_pipeline.fit(trace, trace_label)\n",
        "poly_pred = poly_pipeline.predict(test_trace)\n",
        "rmse_eval('Poly ElasticNet', poly_pred, test_label)"
      ],
      "metadata": {
        "id": "p2JPX1bJG3ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingRegressor, VotingClassifier\n",
        "single_models = [\n",
        "    ('linear_reg', linear_reg), \n",
        "    ('ridge', ridge), \n",
        "    ('lasso', lasso), \n",
        "    ('elasticnet_pipeline', elasticnet_pipeline), \n",
        "    ('poly_pipeline', poly_pipeline)\n",
        "]\n",
        "voting_regressor = VotingRegressor(single_models, n_jobs=-1)\n",
        "voting_regressor.fit(trace, trace_label)\n"
      ],
      "metadata": {
        "id": "Vska8XdZHEli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_pred = voting_regressor.predict(test_trace)\n",
        "rmse_eval('Voting Ensemble', voting_pred, test_label)"
      ],
      "metadata": {
        "id": "z5_Vo8YgHHko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfr = RandomForestRegressor(random_state=42, n_estimators=1000, max_depth=7, max_features=0.9)\n",
        "\n",
        "rfr.fit(trace, trace_label)\n",
        "rfr_pred = rfr.predict(test_trace)\n"
      ],
      "metadata": {
        "id": "GZPKBgduHtde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_eval('RandomForest Ensemble', rfr_pred, test_label)"
      ],
      "metadata": {
        "id": "g-I1-CFqIL5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC, SVR\n",
        "svr = SVR(kernel='rbf', gamma='auto')\n",
        "svr.fit(trace, trace_label)\n",
        "score = svr.score(trace, trace_label)\n",
        "print(\"R-squared: \", score)\n",
        "\n",
        "cv_score = cross_val_score(svr, trace, trace_label, cv=5)\n",
        "print(\"CV mean score: \", cv_score.mean())\n",
        "\n",
        "ypred = svr.predict(test_trace)\n",
        "\n",
        "mse = mean_squared_error(test_label, ypred)\n",
        "print(\"MSE: \", mse)\n",
        "\n",
        "x_ax = range(len(test_label))\n",
        "plt.plot(x_ax, test_trace, label='origianl')\n",
        "plt.plot(x_ax, ypred, label=\"predicted\")\n",
        "plt.title(\"Botson test and predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6UeZgL_jtz8h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}